{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysuLv6mAGYRG"
   },
   "source": [
    "# Text Classification - Deep Learning Sequential Models - LSTMs\n",
    "\n",
    "\n",
    "Another new and interesting approach to supervised deep learning is the use\n",
    "of recurrent neural networks (RNNs) and long short-term memory networks (LSTMs)\n",
    "which also considers the sequence of data (words, events and so on). These are more\n",
    "advanced models than your regular fully connected deep networks and usually take\n",
    "more time to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "CV2VaftX3JO4",
    "outputId": "25dc8167-35f6-4f0b-de32-83b4d4f6301f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 27 20:35:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "Hw7MTNQvzCeG",
    "outputId": "d7badadf-fa6e-4ec4-c862-1b4c919095e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 6.9MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 56.5MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81702 sha256=937e8cc73939b640784216d708230bbf1f4e9f7a924d01ba42cd0f061ca0652c\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.24 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00XtRoYJzLCE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "EiYUcmc2zQzj",
    "outputId": "f27f7a6d-c801-4aef-e8b6-d09bcd0da8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "PxD5STf-zTS9",
    "outputId": "2112f8a8-2406-405d-9d20-6a6701b76118"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZXAHlptzXEJ"
   },
   "outputs": [],
   "source": [
    "# build train and test datasets\n",
    "reviews = dataset['review'].values\n",
    "sentiments = dataset['sentiment'].values\n",
    "\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdf34cuq0W6V"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    doc = contractions.fix(doc)\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()  \n",
    "    norm_docs.append(doc)\n",
    "  \n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "-CRzsnGq0ZSK",
    "outputId": "f780f032-052e-4760-b9cd-de8124408327"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35000/35000 [00:14<00:00, 2365.32it/s]\n",
      "100%|██████████| 15000/15000 [00:06<00:00, 2366.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 115 ms, total: 21.2 s\n",
      "Wall time: 21.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_train_reviews = pre_process_corpus(train_reviews)\n",
    "norm_test_reviews = pre_process_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYjVqlz10c2_"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "To prepare text data for our deep learning model, we transform each review into a sequence.\n",
    "Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n",
    "\n",
    "To perform this transformation, keras provides the ```Tokenizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xf_Ck9Hc0oPo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(norm_train_reviews)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jerA4iHk0qGF",
    "outputId": "fc7e5afc-3d2a-4f58-d25f-1c93ae270aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('dawgis', 175859), ('<PAD>', 0), 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtrRwXbI05Qr"
   },
   "outputs": [],
   "source": [
    "train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
    "test_sequences = t.texts_to_sequences(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Invj0gRk0-RW",
    "outputId": "dd4f856b-8019-44c5-8d2f-fe469b573b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=175860\n",
      "Number of Documents=35000\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "Fq8BhTsM1AX2",
    "outputId": "b6be2227-f6af-4db2-8f38-a72a3dd5e5e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtIAAAFlCAYAAADGTQ/6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcz0lEQVR4nO3df6zl5V0n8PdnGdv1d6ElBIHsoBI3aGKLk5aNxqytC5RudmpSG7obmXSJ/CHdrT82K9U/MK1NqFnbXRJtgjIrmFokWFOypeIs1hgToZ1WhFK2MlJqIRTGDqXuutalfvaP84yeTu+dHw935t459/VKTu73fL7P95zvc8/Nc995vj9OdXcAAIAT8082ewcAAOB0JEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABM2LHZOzDrZS97We/cuXOzdwPghH384x//q+4+e7P341QyZgOnq6ON2adtkN65c2f279+/2bsBcMKq6rObvQ+nmjEbOF0dbcx2agcAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMOGYQbqqLqiqj1TVp6rq4ap666j/QlU9WVUPjMeVS9u8raoOVNWnq+rypfoVo3agqq5fql9YVfeP+m9X1Ys2uqMAALCRjmdG+vkkP9PdFye5NMl1VXXxWPee7n75eNydJGPdVUm+O8kVSX61qs6oqjOS/EqS1ya5OMmbll7nXeO1vjPJs0mu2aD+AWw7VbW3qp6pqk8u1c6qqn1V9ej4eeaoV1XdNCYyHqyqS5a22TPaP1pVe5bq31dVD41tbqqqOrU9BNgajhmku/up7v7EWP7rJI8kOe8om+xOcnt3f7m7P5PkQJJXjseB7n6su/8uye1Jdo8B+NVJ7hzb35rk9bMdAiC/kcVExrLrk9zb3RcluXc8TxaTGxeNx7VJ3pssgneSG5K8Kovx+4bD4Xu0+fGl7Y58L4Bt4YTOka6qnUlekeT+UXrLmMHYuzTAnpfkc0ubPTFq69VfmuSL3f38EfW13v/aqtpfVfsPHjx4IrsOsG109x8lOXREeXcWExXJV09Y7E5yWy/cl+QlVXVuksuT7OvuQ939bJJ9Sa4Y676lu+/r7k5yW0x+ANvUcQfpqvqmJL+T5Ce7+0tZzEh8R5KXJ3kqyS+flD1c0t03d/eu7t519tlnn+y3A1gl53T3U2P580nOGcsnOvlx3lg+sg6w7RxXkK6qr8siRL+vuz+QJN39dHd/pbv/PsmvZXHoL0meTHLB0ubnj9p69S9kMQOy44g6ACfBmEnuk/0+jiICq27HsRqMc5hvSfJId797qX7u0uzGjyQ5fFHLXUl+q6reneTbsjh/7qNJKslFVXVhFkH5qiT/tru7qj6S5A1ZnDe9J8kHN6Jza9l5/YdO1kt/jcdvfN0pey+AY3j68Lg9Ts94ZtSPNvnxL4+o/+Gon79G+6/R3TcnuTlJdu3aNRXcjdnAVnY8M9Lfn+THkrz6iFvd/dK4avvBJD+U5KeSpLsfTnJHkk8l+b0k142Z6+eTvCXJPVlcsHjHaJskP5vkp6vqQBbnTN+ycV0EIItJjsN33liesLgrydXj7h2XJnluTJLck+SyqjpzXANzWZJ7xrovVdWlY6Ll6pzEyQ+AreyYM9Ld/cdZzCYf6e6jbPPOJO9co373Wtt192P5x1NDAHgBqur9Wcwmv6yqnsji7hs3Jrmjqq5J8tkkbxzN705yZRZ3WPqbJG9Oku4+VFXvSPKx0e7t3X34AsafyOLOIF+f5MPjAbDtHDNIA3B66e43rbPqNWu07STXrfM6e5PsXaO+P8n3vJB9BFgFviIcAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATDhmkK6qC6rqI1X1qap6uKreOupnVdW+qnp0/Dxz1KuqbqqqA1X1YFVdsvRae0b7R6tqz1L9+6rqobHNTVVVJ6OzAACwUY5nRvr5JD/T3RcnuTTJdVV1cZLrk9zb3RcluXc8T5LXJrloPK5N8t5kEbyT3JDkVUlemeSGw+F7tPnxpe2ueOFdAwCAk+eYQbq7n+ruT4zlv07ySJLzkuxOcutodmuS14/l3Ulu64X7krykqs5NcnmSfd19qLufTbIvyRVj3bd0933d3UluW3otADZQVf3UOLr4yap6f1X906q6sKruH0cFf7uqXjTavng8PzDW71x6nbeN+qer6vLN6g/AZjqhc6THIPqKJPcnOae7nxqrPp/knLF8XpLPLW32xKgdrf7EGnUANlBVnZfkPybZ1d3fk+SMJFcleVeS93T3dyZ5Nsk1Y5Nrkjw76u8Z7TKOSl6V5LuzOIL4q1V1xqnsC8BWcNxBuqq+KcnvJPnJ7v7S8roxk9wbvG9r7cO1VbW/qvYfPHjwZL8dwCrakeTrq2pHkm9I8lSSVye5c6w/8gjj4SOPdyZ5zbiGZXeS27v7y939mSQHsjhlD2BbOa4gXVVfl0WIfl93f2CUnx6nZWT8fGbUn0xywdLm54/a0ernr1H/Gt19c3fv6u5dZ5999vHsOgBDdz+Z5L8k+cssAvRzST6e5Ivd/fxotnxU8B+OJI71zyV5adY/wvhVTH4Aq+547tpRSW5J8kh3v3tp1V1JDt95Y0+SDy7Vrx5377g0yXPjFJB7klxWVWeOiwwvS3LPWPelqrp0vNfVS68FwAYZY+/uJBcm+bYk35iTeHG3yQ9g1e04jjbfn+THkjxUVQ+M2s8luTHJHVV1TZLPJnnjWHd3kiuzONT3N0nenCTdfaiq3pHkY6Pd27v70Fj+iSS/keTrk3x4PADYWD+c5DPdfTBJquoDWYzxL6mqHWPWefmo4OEjiU+MU0G+NckXsv4RRoBt5ZhBurv/OMl693V+zRrtO8l167zW3iR716jvT/I9x9oXAF6Qv0xyaVV9Q5L/m8UYvj/JR5K8Icnt+dojjHuS/MlY/wfd3VV1V5Lfqqp3ZzGzfVGSj57KjgBsBcczIw3ACuju+6vqziSfyOI7Av40yc1JPpTk9qr6xVG7ZWxyS5LfrKoDSQ5lcaeOdPfDVXVHkk+N17muu79ySjsDsAUI0gDbSHffkMWXYy17LGvcdaO7/zbJj67zOu9M8s4N30GA08gJ3UcaAABYEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmHDMIF1Ve6vqmar65FLtF6rqyap6YDyuXFr3tqo6UFWfrqrLl+pXjNqBqrp+qX5hVd0/6r9dVS/ayA4CAMDJcDwz0r+R5Io16u/p7pePx91JUlUXJ7kqyXePbX61qs6oqjOS/EqS1ya5OMmbRtskedd4re9M8mySa15IhwBYX1W9pKrurKr/VVWPVNW/qKqzqmpfVT06fp452lZV3TQmOh6sqkuWXmfPaP9oVe3ZvB4BbJ5jBunu/qMkh47z9XYnub27v9zdn0lyIMkrx+NAdz/W3X+X5PYku6uqkrw6yZ1j+1uTvP4E+wDA8ftvSX6vu/95ku9N8kiS65Pc290XJbl3PE8Wkx8Xjce1Sd6bJFV1VpIbkrwqi/H9hsPhG2A7eSHnSL9lzFDsXRpAz0vyuaU2T4zaevWXJvlidz9/RB2ADVZV35rkB5PckiTd/Xfd/cUsJkFuHc2WJzR2J7mtF+5L8pKqOjfJ5Un2dfeh7n42yb6sfeQSYKXNBun3JvmOJC9P8lSSX96wPTqKqrq2qvZX1f6DBw+eircEWCUXJjmY5L9X1Z9W1a9X1TcmOae7nxptPp/knLF8opMjANvKVJDu7qe7+yvd/fdJfi2LQ3tJ8mSSC5aanj9q69W/kMUMx44j6uu9783dvau7d5199tkzuw6wne1IckmS93b3K5L8n/zjaRxJku7uJL0Rb2byA1h1U0F6HNo77EeSHL6jx11JrqqqF1fVhVmcV/fRJB9LctG4Q8eLsrgg8a4xYH8kyRvG9nuSfHBmnwA4pieSPNHd94/nd2YRrJ8+PK6Pn8+M9Sc6OfJVTH4Aq+54bn/3/iR/kuS7quqJqromyS9V1UNV9WCSH0ryU0nS3Q8nuSPJp5L8XpLrxsz180nekuSeLC5suWO0TZKfTfLTVXUgi3Omb9nQHgKQJOnuzyf5XFV91yi9Jovx+q4sJjKSr57QuCvJ1ePuHZcmeW6cAnJPksuq6sxxjcxlowawrew4VoPuftMa5XXDbne/M8k716jfneTuNeqP5R9PDQHg5PoPSd43jg4+luTNWUyq3DEmSj6b5I2j7d1JrsziDkx/M9qmuw9V1TuyONqYJG/v7uO9uxPAyjhmkAZgdXT3A0l2rbHqNWu07STXrfM6e5Ps3di9Azi9+IpwAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACccM0lW1t6qeqapPLtXOqqp9VfXo+HnmqFdV3VRVB6rqwaq6ZGmbPaP9o1W1Z6n+fVX10Njmpqqqje4kAABstOOZkf6NJFccUbs+yb3dfVGSe8fzJHltkovG49ok700WwTvJDUleleSVSW44HL5Hmx9f2u7I9wJgg1TVGVX1p1X1P8bzC6vq/jGZ8dtV9aJRf/F4fmCs37n0Gm8b9U9X1eWb0xOAzXfMIN3df5Tk0BHl3UluHcu3Jnn9Uv22XrgvyUuq6twklyfZ192HuvvZJPuSXDHWfUt339fdneS2pdcCYOO9NckjS8/fleQ93f2dSZ5Ncs2oX5Pk2VF/z2iXqro4yVVJvjuLiY9fraozTtG+A2wps+dIn9PdT43lzyc5Zyyfl+RzS+2eGLWj1Z9Yo76mqrq2qvZX1f6DBw9O7jrA9lRV5yd5XZJfH88ryauT3DmaHDkxcnjC5M4krxntdye5vbu/3N2fSXIgiyONANvOC77YcMwk9wbsy/G8183dvau7d5199tmn4i0BVsl/TfKfk/z9eP7SJF/s7ufH8+XJjH+YABnrnxvt15sY+RomP4BVNxuknx6nZWT8fGbUn0xywVK780ftaPXz16gDsIGq6l8neaa7P36q3tPkB7DqZoP0XUkO33ljT5IPLtWvHnfvuDTJc+MUkHuSXFZVZ46LDC9Lcs9Y96WqunQcMrx66bUA2Djfn+TfVNXjSW7P4pSO/5bFtSw7RpvlyYx/mAAZ6781yRey/sQIwLZzPLe/e3+SP0nyXVX1RFVdk+TGJP+qqh5N8sPjeZLcneSxLM6Z+7UkP5Ek3X0oyTuSfGw83j5qGW1+fWzzF0k+vDFdA+Cw7n5bd5/f3TuzuFjwD7r73yX5SJI3jGZHTowcnjB5w2jfo37VuKvHhVncbemjp6gbAFvKjmM16O43rbPqNWu07STXrfM6e5PsXaO+P8n3HGs/ADgpfjbJ7VX1i0n+NMkto35Lkt+sqgNZ3LnpqiTp7oer6o4kn0ryfJLruvsrp363ATbfMYM0AKulu/8wyR+O5ceyxl03uvtvk/zoOtu/M8k7T94eApwefEU4AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmuP0dACTZef2HTun7PX7j607p+wEbz4w0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYMKOzd6BVbbz+g+d0vd7/MbXndL3AwDYzsxIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADDhBQXpqnq8qh6qqgeqav+onVVV+6rq0fHzzFGvqrqpqg5U1YNVdcnS6+wZ7R+tqj0vrEsArKWqLqiqj1TVp6rq4ap666gbtwEmbMSM9A9198u7e9d4fn2Se7v7oiT3judJ8tokF43HtUnemywG8CQ3JHlVklcmueHwIA7Ahno+yc9098VJLk1yXVVdHOM2wJSTcWrH7iS3juVbk7x+qX5bL9yX5CVVdW6Sy5Ps6+5D3f1skn1JrjgJ+wWwrXX3U939ibH810keSXJejNsAU15okO4kv19VH6+qa0ftnO5+aix/Psk5Y/m8JJ9b2vaJUVuv/jWq6tqq2l9V+w8ePPgCdx1g+6qqnUlekeT+nKRx25gNrLoXGqR/oLsvyeLw33VV9YPLK7u7swjbG6K7b+7uXd296+yzz96olwXYVqrqm5L8TpKf7O4vLa/byHHbmA2suhcUpLv7yfHzmSS/m8W5ck+PQ38ZP58ZzZ9McsHS5ueP2np1ADZYVX1dFiH6fd39gVE2bgNMmA7SVfWNVfXNh5eTXJbkk0nuSnL4Cu49ST44lu9KcvW4CvzSJM+NQ4n3JLmsqs4cF6tcNmoAbKCqqiS3JHmku9+9tMq4DTBhxwvY9pwkv7sYl7MjyW919+9V1ceS3FFV1yT5bJI3jvZ3J7kyyYEkf5PkzUnS3Yeq6h1JPjbavb27D72A/QJgbd+f5MeSPFRVD4zazyW5McZtgBM2HaS7+7Ek37tG/QtJXrNGvZNct85r7U2yd3ZfADi27v7jJLXOauM2wAnyzYYAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYIEgDAMAEQRoAACYI0gAAMEGQBgCACYI0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADBBkAYAgAmCNAAATNix2TsAANvRzus/dErf7/EbX3dK3w+2AzPSAAAwQZAGAIAJgjQAAEwQpAEAYIKLDVeIC1cAAE4dM9IAADBBkAYAgAmCNAAATBCkAQBggiANAAATBGkAAJggSAMAwARBGgAAJgjSAAAwQZAGAIAJgjQAAEwQpAEAYIIgDQAAEwRpAACYsGOzdwAAOPl2Xv+hU/Zej9/4ulP2XrCZBGmmGZQBgO3MqR0AADBBkAYAgAmCNAAATHCONACwoU7lNTSJ62jYPFtmRrqqrqiqT1fVgaq6frP3B4D1GbMBtkiQrqozkvxKktcmuTjJm6rq4s3dKwDWYswGWNgSQTrJK5Mc6O7HuvvvktyeZPcm7xMAazNmA2TrnCN9XpLPLT1/IsmrNmlf2IKcbwdbijEbIFsnSB+Xqro2ybXj6f+uqk+f4Eu8LMlfbexebSmr3r/kFPWx3nWy32Fdq/4Z6t/CPzvZO7IVGLOn6fcJ2sQxeyNs1887OX36vu6YvVWC9JNJLlh6fv6ofZXuvjnJzbNvUlX7u3vX7PZb3ar3L1n9Purf6W3V+7fEmH0S6ff2sl37naxG37fKOdIfS3JRVV1YVS9KclWSuzZ5nwBYmzEbIFtkRrq7n6+qtyS5J8kZSfZ298ObvFsArMGYDbCwJYJ0knT33UnuPslvM32I8TSx6v1LVr+P+nd6W/X+/QNj9kml39vLdu13sgJ9r+7e7H0AAIDTzlY5RxoAAE4r2yZIr8rX2VbV41X1UFU9UFX7R+2sqtpXVY+On2eOelXVTaPPD1bVJZu791+rqvZW1TNV9cml2gn3p6r2jPaPVtWezejLWtbp3y9U1ZPjM3ygqq5cWve20b9PV9XlS/Ut+fdbVRdU1Ueq6lNV9XBVvXXUV+IzPEr/VuYz3IpW/Xe1auP40az6GL+eVR/717Pq/xPW1N0r/8jiYpi/SPLtSV6U5M+SXLzZ+zXZl8eTvOyI2i8luX4sX5/kXWP5yiQfTlJJLk1y/2bv/xr9+cEklyT55Gx/kpyV5LHx88yxfOZm9+0o/fuFJP9pjbYXj7/NFye5cPzNnrGV/36TnJvkkrH8zUn+fPRjJT7Do/RvZT7DrfbYDr+rVRvHj9HXlR7jT7DfKz9urPr/hLUe22VGetW/znZ3klvH8q1JXr9Uv60X7kvykqo6dzN2cD3d/UdJDh1RPtH+XJ5kX3cf6u5nk+xLcsXJ3/tjW6d/69md5Pbu/nJ3fybJgSz+drfs3293P9XdnxjLf53kkSy+9W4lPsOj9G89p91nuAVt19/VaTuOH82qj/HrWfWxfz2r/j9hLdslSK/1dbZH+2e4lXWS36+qj9fiW8OS5Jzufmosfz7JOWP5dO33ifbndOznW8ZhrL2HD3HlNO9fVe1M8ook92cFP8Mj+pes4Ge4RWyH39V2GMePZuXGhxOwbcaNVf+fcNh2CdKr5Ae6+5Ikr01yXVX94PLKXhwTWZlbsaxaf4b3JvmOJC9P8lSSX97c3XnhquqbkvxOkp/s7i8tr1uFz3CN/q3cZ8gpta3G8aPZTn3NNho3Vv1/wrLtEqSP6+tsTwfd/eT4+UyS383i0M/Thw/1jZ/PjOana79PtD+nVT+7++nu/kp3/32SX8viM0xO0/5V1ddlMWC+r7s/MMor8xmu1b9V+wy3mJX/XW2TcfxoVmZ8OBHbZdxY9f8JR9ouQXolvs62qr6xqr758HKSy5J8Mou+HL6idU+SD47lu5JcPa6KvTTJc0uHVrayE+3PPUkuq6ozx6Gyy0ZtSzri/MYfyeIzTBb9u6qqXlxVFya5KMlHs4X/fquqktyS5JHufvfSqpX4DNfr3yp9hlvQSv+uttE4fjQrMT6cqO0wbqz6/4Q1zVyheDo+srgy9M+zuAL25zd7fyb78O1ZXLX7Z0kePtyPJC9Ncm+SR5P8zyRnjXol+ZXR54eS7NrsPqzRp/dncYjr/2VxDtQ1M/1J8u+zuEDjQJI3b3a/jtG/3xz7/2AWg8i5S+1/fvTv00leu9X/fpP8QBaH6B5M8sB4XLkqn+FR+rcyn+FWfKzy72oVx/Fj9Helx/gT7PfKjxur/j9hrYdvNgQAgAnb5dQOAADYUII0AABMEKQBAGCCIA0AABMEaQAAmCBIAwDABEEaAAAmCNIAADDh/wMtdVI3tMZ2PQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_lens = [len(s) for s in train_sequences]\n",
    "test_lens = [len(s) for s in test_sequences]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "h1 = ax[0].hist(train_lens)\n",
    "h2 = ax[1].hist(test_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5ZMlD241CVr"
   },
   "source": [
    "### Sequence Normalization\n",
    "\n",
    "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length.\n",
    "For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CaP_1s41GCL"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Op62mTZT1M4B",
    "outputId": "b5483c21-4772-42e5-e04f-5bb9d71d1882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 1000), (15000, 1000))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZZ1lLQw1Ols"
   },
   "source": [
    "### Encoding Labels\n",
    "\n",
    "The dataset contains labels of the form positive/negative. The following step encodes the labels using ```sklearn's``` ```LabelEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRBnWQGb1cRM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOPPNySt1eDz"
   },
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(train_sentiments)\n",
    "y_test = le.transform(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwlYATD11prp"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1ScFo641sFW"
   },
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaPlrBcU-3av"
   },
   "source": [
    "# Build Model Architecture\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "\n",
    "The Embedding layer helps us generate the word embeddings from scratch. This layer\n",
    "is also initialized with some weights and is updated based on our optimizer, similar to\n",
    "weights on the neuron units in other layers when the network tries to minimize the loss\n",
    "in each epoch. Thus, the embedding layer tries to optimize its weights such that we get\n",
    "the best word embeddings that will generate minimum error in the model and capture\n",
    "semantic similarity and relationships among words. How do we get the embeddings?\n",
    "Let’s say we have a review with three terms ['movie', 'was', 'good'] and a vocab_map\n",
    "consisting of word to index mappings for 175860 words. \n",
    "\n",
    "![](https://i.imgur.com/WuV47DW.png)\n",
    "\n",
    "\n",
    "# LSTM\n",
    "\n",
    "LSTMs try to overcome\n",
    "the shortcomings of RNN models, especially with regard to handling long-term\n",
    "dependencies and problems that occur when the weight matrix associated with the\n",
    "units (neurons) become too small (leading to vanishing gradient) or too large (leading to\n",
    "exploding gradient). These architectures are more complex than regular deep networks\n",
    "and going into detailed internals and math concepts are out of the current scope, but we\n",
    "will try to cover the essentials here without making it math heavy\n",
    "\n",
    "![](https://i.imgur.com/c8qGKX8.png)\n",
    "\n",
    "The sequence of operations in the LSTM cell is briefly shown as follows.\n",
    "\n",
    "![](https://i.imgur.com/uiIbDk1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "_M8LbmqR1vbO",
    "outputId": "6ec34ddd-d749-4674-8633-142322010338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 300)         52758000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 53,010,929\n",
      "Trainable params: 53,010,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 128 # total LSTM units\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(tf.keras.layers.SpatialDropout1D(0.1))\n",
    "model.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRB4rNgo-533"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "uPqowrsh2vFb",
    "outputId": "7c78b7e2-5051-4488-a35d-d8bfc0bb1197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 151s 611ms/step - loss: 0.4077 - accuracy: 0.8127 - val_loss: 0.4319 - val_accuracy: 0.7954\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 152s 614ms/step - loss: 0.1864 - accuracy: 0.9312 - val_loss: 0.3629 - val_accuracy: 0.8817\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 147s 596ms/step - loss: 0.0879 - accuracy: 0.9690 - val_loss: 0.4088 - val_accuracy: 0.8574\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9800Restoring model weights from the end of the best epoch.\n",
      "247/247 [==============================] - 148s 599ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.5659 - val_accuracy: 0.8549\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f4a118320>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=2,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n",
    "          callbacks=[es],\n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EzC-IW9-7sm"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kQvfAor127iS",
    "outputId": "456505dc-9375-4fcc-ab5b-0c556bf0f5d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 13s 27ms/step - loss: 0.3475 - accuracy: 0.8855\n",
      "Accuracy: 88.55%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "p_LePG_y4IX5",
    "outputId": "7d9fdc16-6233-4ea3-b984-8a6ea9479399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-cb5d9830b2ab>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test).ravel()\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "JCifYtx04Ia1",
    "outputId": "2b65104d-90c5-4eb4-cfa3-782062f1fc34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "GFUgpD9E4IgE",
    "outputId": "b993ffb8-3774-425b-f16c-9c015fb64464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88      7490\n",
      "    positive       0.87      0.91      0.89      7510\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.89      0.89     15000\n",
      "weighted avg       0.89      0.89      0.89     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6464</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>692</td>\n",
       "      <td>6818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6464      1026\n",
       "positive       692      6818"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fq9Ccs3Y-_Fh"
   },
   "source": [
    "# Stacked LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aMSEnyBE_BSU"
   },
   "source": [
    "## Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "8As3OAUg4Ijb",
    "outputId": "cd028680-7cc5-4e23-d14c-1139c2293a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1000, 300)         52758000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1000, 128)         219648    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 53,142,513\n",
      "Trainable params: 53,142,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model2.add(tf.keras.layers.SpatialDropout1D(0.1))\n",
    "model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True))\n",
    "model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
    "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYwqw31s_Ehx"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "atBaIleW5RWI",
    "outputId": "e79b3354-416f-4df2-d6d6-074833620356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 169s 683ms/step - loss: 0.4110 - accuracy: 0.8120 - val_loss: 0.3208 - val_accuracy: 0.8703\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 164s 666ms/step - loss: 0.1577 - accuracy: 0.9452 - val_loss: 0.3205 - val_accuracy: 0.8786\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 163s 660ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 0.4807 - val_accuracy: 0.8663\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9676Restoring model weights from the end of the best epoch.\n",
      "247/247 [==============================] - 163s 659ms/step - loss: 0.0950 - accuracy: 0.9676 - val_loss: 0.4461 - val_accuracy: 0.8417\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e08534c18>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=2,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n",
    "           callbacks=[es],\n",
    "           shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLUkLa-d_IrV"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lGDVL22K5UZ_",
    "outputId": "4646c63e-c906-4e29-b7d6-00e152423e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 20s 43ms/step - loss: 0.3084 - accuracy: 0.8850\n",
      "Accuracy: 88.50%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model2.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wHnuwJNW5VUT",
    "outputId": "75d07761-52c1-4e47-c626-96b53072ef61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model2.predict_classes(X_test).ravel()\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "ksyEEPA25XeU",
    "outputId": "5d0d7433-c10a-43c5-d414-9b8e0ab177b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "jMS7pZ3a5XjD",
    "outputId": "16807f6c-6cae-4713-ffc4-6e89b6713698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88      7490\n",
      "    positive       0.88      0.89      0.89      7510\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.88      0.88     15000\n",
      "weighted avg       0.89      0.89      0.88     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6587</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>822</td>\n",
       "      <td>6688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6587       903\n",
       "positive       822      6688"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "11-NLP Applications - Deep Learning Sequential Models - LSTMs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
